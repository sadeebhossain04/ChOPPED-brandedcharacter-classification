{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c8553b-66b3-43e6-9a4a-194509122441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models, utils\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# For inline plotting in Jupyter Notebook\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79158d16-f7ac-48ac-8543-75000ea5adeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for the ZIP file and extraction folder\n",
    "zip_path = \"BCImages.zip\"\n",
    "extraction_path = \"./BCImages\"\n",
    "\n",
    "# Extract the ZIP file\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extraction_path)\n",
    "\n",
    "print(f\"Extracted contents to: {extraction_path}\")\n",
    "print(\"Extracted folders and files:\", os.listdir(extraction_path))\n",
    "\n",
    "# Inspect the contents of each folder within the extraction directory\n",
    "for folder in os.listdir(extraction_path):\n",
    "    folder_path = os.path.join(extraction_path, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        print(f\"Contents of {folder_path}: {os.listdir(folder_path)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6021ab86-2bdc-4072-af71-a73b338dfd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and split ratios\n",
    "base_folder = \"./BCImages/BrandedCharacters_Images\"\n",
    "output_base_folder = \"./SplitDataset\"\n",
    "train_ratio, val_ratio, test_ratio = 0.7, 0.15, 0.15\n",
    "\n",
    "# Create directories for each split\n",
    "for split in ['train', 'val', 'test']:\n",
    "    os.makedirs(os.path.join(output_base_folder, split), exist_ok=True)\n",
    "\n",
    "# Iterate through each character folder and split images\n",
    "for character in os.listdir(base_folder):\n",
    "    character_path = os.path.join(base_folder, character)\n",
    "    if os.path.isdir(character_path):\n",
    "        print(f\"Processing character: {character}\")\n",
    "        images = [img for img in os.listdir(character_path) if img.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        \n",
    "        # Split images into training and temporary sets, then split temp into val and test\n",
    "        train_imgs, temp_imgs = train_test_split(images, test_size=(1 - train_ratio), random_state=42)\n",
    "        val_imgs, test_imgs = train_test_split(temp_imgs, test_size=(test_ratio / (val_ratio + test_ratio)), random_state=42)\n",
    "        \n",
    "        # Create subdirectories and copy images to the appropriate folder\n",
    "        for split, imgs in zip(['train', 'val', 'test'], [train_imgs, val_imgs, test_imgs]):\n",
    "            split_dir = os.path.join(output_base_folder, split, character)\n",
    "            os.makedirs(split_dir, exist_ok=True)\n",
    "            for img in imgs:\n",
    "                shutil.copy(os.path.join(character_path, img), os.path.join(split_dir, img))\n",
    "        \n",
    "        print(f\"Finished processing {character}:\")\n",
    "        print(f\"  Train: {len(train_imgs)} images\")\n",
    "        print(f\"  Validation: {len(val_imgs)} images\")\n",
    "        print(f\"  Test: {len(test_imgs)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af46c44-50b3-4a98-b0d8-edfb16691a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image transformations for training, validation, and testing\n",
    "transform = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),  # Data augmentation for training\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = \"./SplitDataset\"\n",
    "image_datasets = {\n",
    "    'train': datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform['train']),\n",
    "    'val': datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform['val']),\n",
    "    'test': datasets.ImageFolder(os.path.join(data_dir, 'test'), transform=transform['test']),\n",
    "}\n",
    "\n",
    "batch_size = 32\n",
    "dataloaders = {\n",
    "    x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=(x=='train'))\n",
    "    for x in ['train', 'val', 'test']\n",
    "}\n",
    "\n",
    "# Get class names from the training dataset\n",
    "class_names = image_datasets['train'].classes\n",
    "print(f\"Classes: {class_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0b475c-9699-4043-8175-78db07628928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d205f77a-6bf5-4766-be50-634cbd576dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Display image for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std  = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean  # Unnormalize\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Display a batch from each split (train, val, test)\n",
    "for split in ['train', 'val', 'test']:\n",
    "    inputs, labels = next(iter(dataloaders[split]))\n",
    "    out = utils.make_grid(inputs[:8])\n",
    "    titles = [class_names[x] for x in labels[:8]]\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.title(f\"{split.capitalize()} Batch: \" + \", \".join(titles))\n",
    "    imshow(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6fd314-0fbd-4b10-a7de-55339e433438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained ResNet18 model and modify its final layer\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "num_classes = len(class_names)\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, num_classes)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "# Define loss function, optimizer, and learning rate scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "num_epochs = 10\n",
    "best_val_acc = 0.0\n",
    "\n",
    "# Lists for storing training history (for plotting later)\n",
    "train_acc_history = []\n",
    "val_acc_history = []\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print('-' * 10)\n",
    "    \n",
    "    # Training phase\n",
    "    resnet.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    for inputs, labels in dataloaders['train']:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_correct += torch.sum(preds == labels.data)\n",
    "    \n",
    "    train_loss = train_loss / len(image_datasets['train'])\n",
    "    train_acc = train_correct.double() / len(image_datasets['train'])\n",
    "    train_loss_history.append(train_loss)\n",
    "    train_acc_history.append(train_acc.item())\n",
    "    \n",
    "    # Validation phase\n",
    "    resnet.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloaders['val']:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = resnet(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_correct += torch.sum(preds == labels.data)\n",
    "    \n",
    "    val_loss = val_loss / len(image_datasets['val'])\n",
    "    val_acc = val_correct.double() / len(image_datasets['val'])\n",
    "    val_loss_history.append(val_loss)\n",
    "    val_acc_history.append(val_acc.item())\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    # Save the best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(resnet.state_dict(), 'best_resnet_model.pth')\n",
    "    \n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd081221-e7e4-4066-b2d9-2f241e3a62a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model and evaluate on the test set\n",
    "resnet.load_state_dict(torch.load('best_resnet_model.pth'))\n",
    "resnet.eval()\n",
    "\n",
    "test_correct = 0\n",
    "all_preds = []      # To store predicted labels\n",
    "all_labels = []     # To store true labels\n",
    "all_probs = []      # To store output probabilities\n",
    "\n",
    "# For error analysis (misclassified examples)\n",
    "incorrect_images = []\n",
    "incorrect_predictions = []\n",
    "incorrect_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in dataloaders['test']:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = resnet(inputs)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        test_correct += torch.sum(preds == labels.data)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_probs.append(probs.cpu().numpy())\n",
    "        \n",
    "        # Collect misclassified images for later visualization\n",
    "        for i in range(inputs.size(0)):\n",
    "            if preds[i] != labels[i]:\n",
    "                incorrect_images.append(inputs[i].cpu())\n",
    "                incorrect_predictions.append(class_names[preds[i]])\n",
    "                incorrect_true_labels.append(class_names[labels[i]])\n",
    "\n",
    "test_acc = test_correct.double() / len(image_datasets['test'])\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Total Correct Predictions: {test_correct.item()}\")\n",
    "print(f\"Total Incorrect Predictions: {len(all_labels) - test_correct.item()}\")\n",
    "\n",
    "# Concatenate all probability arrays from each batch\n",
    "all_probs = np.concatenate(all_probs, axis=0)\n",
    "all_labels_np = np.array(all_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e737b62-46cc-4a61-9f83-fd74258f549c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 1. Plot Training vs. Validation Accuracy and Loss\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, len(train_acc_history) + 1), train_acc_history, label='Train Accuracy')\n",
    "plt.plot(range(1, len(val_acc_history) + 1), val_acc_history, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs. Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, len(train_loss_history) + 1), train_loss_history, label='Train Loss')\n",
    "plt.plot(range(1, len(val_loss_history) + 1), val_loss_history, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs. Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Confusion Matrix and Classification Report\n",
    "cm = confusion_matrix(all_labels_np, np.array(all_preds))\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels_np, np.array(all_preds), target_names=class_names))\n",
    "\n",
    "# 3. ROC Curves for Each Class (One-vs-Rest)\n",
    "num_classes = len(class_names)\n",
    "y_test_bin = label_binarize(all_labels_np, classes=list(range(num_classes)))\n",
    "\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], all_probs[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and AUC\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), all_probs.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(num_classes):\n",
    "    plt.plot(fpr[i], tpr[i], lw=2,\n",
    "             label=f'ROC curve of {class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label=f'Micro-average ROC (AUC = {roc_auc[\"micro\"]:.2f})',\n",
    "         color='navy', linestyle='--', linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multiclass ROC Curves')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# 4. Prediction Confidence Histogram\n",
    "all_confidences = [np.max(prob) for prob in all_probs]\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(all_confidences, bins=20, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Prediction Confidence')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Prediction Confidences')\n",
    "plt.show()\n",
    "\n",
    "# 5. Visualize Some Misclassified Examples\n",
    "plt.figure(figsize=(15, 10))\n",
    "num_images_to_show = 8  \n",
    "for i in range(min(len(incorrect_images), num_images_to_show)):\n",
    "    plt.subplot(2, 4, i + 1)\n",
    "    imshow(incorrect_images[i])\n",
    "    plt.title(f\"Pred: {incorrect_predictions[i]}\\nTrue: {incorrect_true_labels[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn_env",
   "language": "python",
   "name": "cnn_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
